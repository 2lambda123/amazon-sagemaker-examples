{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uq pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cultural-template",
   "metadata": {
    "papermill": {
     "duration": 0.008999,
     "end_time": "2021-06-21T00:09:03.934872",
     "exception": false,
     "start_time": "2021-06-21T00:09:03.925873",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Regression with Amazon SageMaker XGBoost (Parquet input)\n",
    "\n",
    "This notebook exhibits the use of a Parquet dataset for use with the SageMaker XGBoost algorithm. The example here is almost the same as [Regression with Amazon SageMaker XGBoost algorithm](xgboost_abalone.ipynb).\n",
    "\n",
    "This notebook tackles the exact same problem with the same solution, but has been modified for a Parquet input. \n",
    "The original notebook provides details of dataset and the machine learning use-case.\n",
    "\n",
    "This notebook has been tested using the Python 3 (Data Science) kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-stuart",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-21T00:09:03.952939Z",
     "iopub.status.busy": "2021-06-21T00:09:03.952208Z",
     "iopub.status.idle": "2021-06-21T00:09:05.194773Z",
     "shell.execute_reply": "2021-06-21T00:09:05.195223Z"
    },
    "papermill": {
     "duration": 1.253257,
     "end_time": "2021-06-21T00:09:05.195369",
     "exception": false,
     "start_time": "2021-06-21T00:09:03.942112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import re\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "# S3 bucket for saving code and model artifacts.\n",
    "# Feel free to specify a different bucket here if you wish.\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "prefix = \"sagemaker/DEMO-xgboost-parquet\"\n",
    "bucket_path = \"https://s3-{}.amazonaws.com/{}\".format(region, bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "social-storm",
   "metadata": {
    "papermill": {
     "duration": 0.00574,
     "end_time": "2021-06-21T00:09:05.207074",
     "exception": false,
     "start_time": "2021-06-21T00:09:05.201334",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We will use [PyArrow](https://arrow.apache.org/docs/python/) library to store the Abalone dataset in the Parquet format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-position",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-21T00:09:10.239125Z",
     "iopub.status.busy": "2021-06-21T00:09:10.238632Z",
     "iopub.status.idle": "2021-06-21T00:09:11.012982Z",
     "shell.execute_reply": "2021-06-21T00:09:11.013368Z"
    },
    "papermill": {
     "duration": 0.805388,
     "end_time": "2021-06-21T00:09:11.013509",
     "exception": false,
     "start_time": "2021-06-21T00:09:10.208121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "\n",
    "# Download the dataset and load into a pandas dataframe\n",
    "FILE_NAME = \"abalone.csv\"\n",
    "urllib.request.urlretrieve(\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data\", FILE_NAME\n",
    ")\n",
    "feature_names = [\n",
    "    \"Sex\",\n",
    "    \"Length\",\n",
    "    \"Diameter\",\n",
    "    \"Height\",\n",
    "    \"Whole weight\",\n",
    "    \"Shucked weight\",\n",
    "    \"Viscera weight\",\n",
    "    \"Shell weight\",\n",
    "    \"Rings\",\n",
    "]\n",
    "data = pd.read_csv(FILE_NAME, header=None, names=feature_names)\n",
    "\n",
    "# SageMaker XGBoost has the convention of label in the first column\n",
    "data = data[feature_names[-1:] + feature_names[:-1]]\n",
    "data[\"Sex\"] = data[\"Sex\"].astype(\"category\").cat.codes\n",
    "\n",
    "# Split the downloaded data into train/test dataframes\n",
    "train, test = np.split(data.sample(frac=1), [int(0.8 * len(data))])\n",
    "\n",
    "# requires PyArrow installed\n",
    "train.to_parquet(\"abalone_train.parquet\")\n",
    "test.to_parquet(\"abalone_test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-warehouse",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-21T00:09:11.074296Z",
     "iopub.status.busy": "2021-06-21T00:09:11.073781Z",
     "iopub.status.idle": "2021-06-21T00:09:11.148763Z",
     "shell.execute_reply": "2021-06-21T00:09:11.148337Z"
    },
    "papermill": {
     "duration": 0.111246,
     "end_time": "2021-06-21T00:09:11.148873",
     "exception": false,
     "start_time": "2021-06-21T00:09:11.037627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "sagemaker.Session().upload_data(\n",
    "    \"abalone_train.parquet\", bucket=bucket, key_prefix=prefix + \"/\" + \"train\"\n",
    ")\n",
    "\n",
    "sagemaker.Session().upload_data(\n",
    "    \"abalone_test.parquet\", bucket=bucket, key_prefix=prefix + \"/\" + \"test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prime-diana",
   "metadata": {
    "papermill": {
     "duration": 0.023341,
     "end_time": "2021-06-21T00:09:11.196209",
     "exception": false,
     "start_time": "2021-06-21T00:09:11.172868",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We obtain the new container by specifying the framework version (0.90-1). This version specifies the upstream XGBoost framework version (0.90) and an additional SageMaker version (1). If you have an existing XGBoost workflow based on the previous (0.72) container, this would be the only change necessary to get the same workflow working with the new container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-principal",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-21T00:09:11.250268Z",
     "iopub.status.busy": "2021-06-21T00:09:11.249389Z",
     "iopub.status.idle": "2021-06-21T00:09:11.260401Z",
     "shell.execute_reply": "2021-06-21T00:09:11.260760Z"
    },
    "papermill": {
     "duration": 0.040939,
     "end_time": "2021-06-21T00:09:11.260892",
     "exception": false,
     "start_time": "2021-06-21T00:09:11.219953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "container = get_image_uri(region, \"xgboost\", \"0.90-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-tucson",
   "metadata": {
    "papermill": {
     "duration": 0.024102,
     "end_time": "2021-06-21T00:09:11.309310",
     "exception": false,
     "start_time": "2021-06-21T00:09:11.285208",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "After setting training parameters, we kick off training, and poll for status until training is completed, which in this example, takes between 5 and 6 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-sitting",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-21T00:09:11.372458Z",
     "iopub.status.busy": "2021-06-21T00:09:11.368669Z",
     "iopub.status.idle": "2021-06-21T00:13:12.030973Z",
     "shell.execute_reply": "2021-06-21T00:13:12.031388Z"
    },
    "papermill": {
     "duration": 240.698296,
     "end_time": "2021-06-21T00:13:12.031529",
     "exception": false,
     "start_time": "2021-06-21T00:09:11.333233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "\n",
    "job_name = \"xgboost-parquet-example-training-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(\"Training job\", job_name)\n",
    "\n",
    "# Ensure that the training and validation data folders generated above are reflected in the \"InputDataConfig\" parameter below.\n",
    "\n",
    "create_training_params = {\n",
    "    \"AlgorithmSpecification\": {\"TrainingImage\": container, \"TrainingInputMode\": \"Pipe\"},\n",
    "    \"RoleArn\": role,\n",
    "    \"OutputDataConfig\": {\"S3OutputPath\": bucket_path + \"/\" + prefix + \"/single-xgboost\"},\n",
    "    \"ResourceConfig\": {\"InstanceCount\": 1, \"InstanceType\": \"ml.m5.24xlarge\", \"VolumeSizeInGB\": 20},\n",
    "    \"TrainingJobName\": job_name,\n",
    "    \"HyperParameters\": {\n",
    "        \"max_depth\": \"5\",\n",
    "        \"eta\": \"0.2\",\n",
    "        \"gamma\": \"4\",\n",
    "        \"min_child_weight\": \"6\",\n",
    "        \"subsample\": \"0.7\",\n",
    "        \"silent\": \"0\",\n",
    "        \"objective\": \"reg:linear\",\n",
    "        \"num_round\": \"10\",\n",
    "    },\n",
    "    \"StoppingCondition\": {\"MaxRuntimeInSeconds\": 3600},\n",
    "    \"InputDataConfig\": [\n",
    "        {\n",
    "            \"ChannelName\": \"train\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": bucket_path + \"/\" + prefix + \"/train\",\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\",\n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"application/x-parquet\",\n",
    "            \"CompressionType\": \"None\",\n",
    "        },\n",
    "        {\n",
    "            \"ChannelName\": \"validation\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": bucket_path + \"/\" + prefix + \"/test\",\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\",\n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"application/x-parquet\",\n",
    "            \"CompressionType\": \"None\",\n",
    "        },\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "client = boto3.client(\"sagemaker\", region_name=region)\n",
    "client.create_training_job(**create_training_params)\n",
    "\n",
    "status = client.describe_training_job(TrainingJobName=job_name)[\"TrainingJobStatus\"]\n",
    "print(status)\n",
    "while status != \"Completed\" and status != \"Failed\":\n",
    "    time.sleep(60)\n",
    "    status = client.describe_training_job(TrainingJobName=job_name)[\"TrainingJobStatus\"]\n",
    "    print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-single",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-21T00:13:12.090133Z",
     "iopub.status.busy": "2021-06-21T00:13:12.089359Z",
     "iopub.status.idle": "2021-06-21T00:13:13.031405Z",
     "shell.execute_reply": "2021-06-21T00:13:13.030928Z"
    },
    "papermill": {
     "duration": 0.97412,
     "end_time": "2021-06-21T00:13:13.031511",
     "exception": false,
     "start_time": "2021-06-21T00:13:12.057391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sagemaker.analytics import TrainingJobAnalytics\n",
    "\n",
    "metric_name = \"validation:rmse\"\n",
    "\n",
    "metrics_dataframe = TrainingJobAnalytics(\n",
    "    training_job_name=job_name, metric_names=[metric_name]\n",
    ").dataframe()\n",
    "plt = metrics_dataframe.plot(\n",
    "    kind=\"line\", figsize=(12, 5), x=\"timestamp\", y=\"value\", style=\"b.\", legend=False\n",
    ")\n",
    "plt.set_ylabel(metric_name);"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Environment (conda_anaconda3)",
   "language": "python",
   "name": "conda_anaconda3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}