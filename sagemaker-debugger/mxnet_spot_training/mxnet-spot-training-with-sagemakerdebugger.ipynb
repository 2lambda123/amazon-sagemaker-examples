{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "charged-batch",
   "metadata": {
    "papermill": {
     "duration": 0.00787,
     "end_time": "2021-05-27T00:12:08.019514",
     "exception": false,
     "start_time": "2021-05-27T00:12:08.011644",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Enable Spot Training with Amazon SageMaker Debugger\n",
    "\n",
    "Amazon SageMaker Debugger is a new capability of Amazon SageMaker that allows debugging machine learning training. \n",
    "It lets you go beyond just looking at scalars like losses and accuracies during training and gives you full visibility into all tensors 'flowing through the graph' during training. Amazon SageMaker Debugger helps you to monitor your training in near real time using rules and would provide you alerts, once it has detected inconsistency in training flow.\n",
    "\n",
    "Using Amazon SageMaker Debugger is a two step process: Saving tensors and Analysis.\n",
    "\n",
    "### Saving tensors\n",
    "Tensors define the state of the training job at any particular instant in its lifecycle. Debugger exposes a library which allows you to capture these tensors and save them for analysis.\n",
    "\n",
    "### Analysis\n",
    "There are two ways to get to tensors and run analysis on them. One way is to use concept called ***Rules***. For more information about a rules-based approach to analysis, see [Rules](https://github.com/awslabs/sagemaker-debugger/blob/master/docs/analysis.md#Rules). You can also perform interactive analysis in a notebook. Please refer to our other notebooks on how to do that.\n",
    "\n",
    "## Spot Training\n",
    "This notebook talks about how Amazon SageMaker Debugger feature can also be used with Spot Training. For more information related to spot training in Amazon SageMaker please see [Spot Training](https://docs.aws.amazon.com/sagemaker/latest/dg/model-managed-spot-training.html).\n",
    "\n",
    "The examples uses a small gluon CNN model and trains it on the FashionMNIST dataset. If during the training spot instance terminates, the training and analysis of tensors will continue from the last saved checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "covered-chemical",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T00:12:08.031541Z",
     "iopub.status.busy": "2021-05-27T00:12:08.030851Z",
     "iopub.status.idle": "2021-05-27T00:12:08.451372Z",
     "shell.execute_reply": "2021-05-27T00:12:08.450953Z"
    },
    "papermill": {
     "duration": 0.427655,
     "end_time": "2021-05-27T00:12:08.451490",
     "exception": false,
     "start_time": "2021-05-27T00:12:08.023835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import os\n",
    "from sagemaker.mxnet import MXNet\n",
    "from sagemaker.debugger import Rule, rule_configs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blind-partner",
   "metadata": {
    "papermill": {
     "duration": 0.004351,
     "end_time": "2021-05-27T00:12:08.460327",
     "exception": false,
     "start_time": "2021-05-27T00:12:08.455976",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Configuring the inputs for the training job\n",
    "\n",
    "Now call the Amazon SageMaker MXNet Estimator to kick off a training job along with enabling Debugger functionality.\n",
    "\n",
    "- `entrypoint_script` points to the simple MXNet training script that is ran by training job\n",
    "- `hyperparameters` are the parameters that will be passed to the training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "featured-canyon",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T00:12:08.480006Z",
     "iopub.status.busy": "2021-05-27T00:12:08.479557Z",
     "iopub.status.idle": "2021-05-27T00:12:08.522938Z",
     "shell.execute_reply": "2021-05-27T00:12:08.522545Z"
    },
    "papermill": {
     "duration": 0.058413,
     "end_time": "2021-05-27T00:12:08.523045",
     "exception": false,
     "start_time": "2021-05-27T00:12:08.464632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the SageMaker Session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Define the entrypoint script\n",
    "entrypoint_script = \"mxnet_gluon_spot_training.py\"\n",
    "hyperparameters = {\"batch-size\": 100, \"epochs\": 5, \"checkpoint-path\": \"/opt/ml/checkpoints\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-lighting",
   "metadata": {
    "papermill": {
     "duration": 0.00437,
     "end_time": "2021-05-27T00:12:08.531948",
     "exception": false,
     "start_time": "2021-05-27T00:12:08.527578",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training MXNet models in Amazon SageMaker with Amazon SageMaker Debugger\n",
    "\n",
    "Train a small MXNet CNN model with the FashonMNIST dataset in this notebook, with Amazon SageMaker Debugger enabled. This is done using an Amazon SageMaker MXNet 1.6.0 container with script mode. Amazon SageMaker Debugger currently works with Python3, so be sure to set `py_version='py3'` when creating the Amazon SageMaker Estimator.\n",
    "\n",
    "\n",
    "## Enable Amazon SageMaker Debugger and Spot Training in Estimator object\n",
    "\n",
    "Enabling Amazon SageMaker Debugger in training job can be accomplished by adding its configuration into Estimator object constructor:\n",
    "\n",
    "```python\n",
    "sagemaker_simple_estimator = MXNet(...,\n",
    "    # Parameters required to enable spot training.\n",
    "    train_use_spot_instances=True, #Set it to True to enable spot training.\n",
    "    train_max_wait = 10000  # This should be equal to or greater than train_max_run in seconds'\n",
    "    checkpoint_local_path = '/opt/ml/checkpoints/' # This is local path where checkpoints will be stored during training. Default path is /opt/ml/checkpoints'.The training script should generate the checkpoints.\n",
    "    checkpoint_s3_uri = 's3://bucket/prefix' # Uri to S3 bucket where the checkpoints captured by the model will be stored.\n",
    "    ## Rule Parameter\n",
    "    rules = [Rule.sagemaker(rule_configs.vanishing_gradient())]\n",
    ")\n",
    "```\n",
    "In this section, we will focus on parameters that are needed to enable Spot Training. \n",
    "\n",
    "- `train_use_spot_instance` : This parameter should be set to 'True' to enable the spot training.\n",
    "- `train_max_wait` : This parameter (in seconds) should be set equal to or greater than 'train_max_run'. \n",
    "- `checkpoint_s3_uri` : This is URI to S3 bucket where the checkpoints will be stored before the spot instance terminated. Once the training is resumed, the checkpoints from this S3 bucket will be restored to 'checkpoint_local_path' in the new instance. Ensure that the S3 bucket is created in the same region as that of current session.\n",
    "- `checkpoint_local_path`: This is the local path where the model will save the checkpoints perodically. The default path is set to '/opt/ml/checkpoints'. Ensure that the model under training is saving the checkpoints in this path. Note that in hyperparameters we are setting 'checkpoint-path' so that the training script will save the checkpoints in that directory.\n",
    "\n",
    "\n",
    "### Rule Parameter\n",
    "We are going to run the *vanishing_gradient* rule during this training. By specifying this parameter, we are enabling the Amazon SageMaker Debugger functionality to collect the *gradients* during this training. The *gradients* will be collected every 500th step as part of the default configurations for this Rule.\n",
    "\n",
    "\n",
    "## How Spot Training works with Amazon SageMaker Debugger\n",
    "\n",
    "Amazon SageMaker Debugger can be enabled even for training with Spot Instances. Spot instances can be interrupted, causing jobs to take longer to start or finish. To leverage the managed spot instance support that Amazon SageMaker provides, you need to configure your training job to save checkpoints. Amazon SageMaker copies checkpoint data from a local path to Amazon S3. When the job is restarted on a different instance, Amazon SageMaker copies the data from Amazon S3 back into the local path. The training can then resume from the last checkpoint instead of restarting.\n",
    "\n",
    "Amazon SageMaker Debugger relies on the checkpoints mechanism to continue emitting tensors from the last saved checkpoint. The Amazon SageMaker Debugger saves the metadata containing last saved state whenver user creates a checkpoint in *checkpoint_local_path*. Along with the checkpoints, this metadata also gets saved to Amazon S3 when the instance is interrupted. Upon restart, along with the checkpoints, this metadata is also copied back to the instance. The Amazon SageMaker Debugger reads the last saved state from the metadata and continues to emit the tensors from that step. This minimizes the emission of duplicate tensors. Note that currently, the rule job continues to wait till even if the training job is interrupted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "occupied-folks",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T00:12:08.544087Z",
     "iopub.status.busy": "2021-05-27T00:12:08.543653Z",
     "iopub.status.idle": "2021-05-27T00:12:08.774858Z",
     "shell.execute_reply": "2021-05-27T00:12:08.775281Z"
    },
    "papermill": {
     "duration": 0.239152,
     "end_time": "2021-05-27T00:12:08.775428",
     "exception": false,
     "start_time": "2021-05-27T00:12:08.536276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make sure to set this to your bucket and location\n",
    "# Ensure that the bucket exists in the same region as that of current region.\n",
    "BUCKET_NAME = sagemaker_session.default_bucket()\n",
    "LOCATION_IN_BUCKET = \"smdebug-checkpoints\"\n",
    "\n",
    "checkpoint_s3_bucket = \"s3://{BUCKET_NAME}/{LOCATION_IN_BUCKET}\".format(\n",
    "    BUCKET_NAME=BUCKET_NAME, LOCATION_IN_BUCKET=LOCATION_IN_BUCKET\n",
    ")\n",
    "\n",
    "# Local path where the model will save its checkpoints.\n",
    "checkpoint_local_path = \"/opt/ml/checkpoints\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "temporal-strength",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T00:12:08.797515Z",
     "iopub.status.busy": "2021-05-27T00:12:08.796971Z",
     "iopub.status.idle": "2021-05-27T00:12:09.196489Z",
     "shell.execute_reply": "2021-05-27T00:12:09.196837Z"
    },
    "papermill": {
     "duration": 0.416757,
     "end_time": "2021-05-27T00:12:09.196971",
     "exception": false,
     "start_time": "2021-05-27T00:12:08.780214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_max_run has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_use_spot_instances has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_max_wait has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_volume_size has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "estimator = MXNet(\n",
    "    role=sagemaker.get_execution_role(),\n",
    "    base_job_name=\"smdebugger-spot-training-demo-mxnet\",\n",
    "    train_instance_count=1,\n",
    "    train_instance_type=\"ml.m4.xlarge\",\n",
    "    train_volume_size=400,\n",
    "    entry_point=entrypoint_script,\n",
    "    hyperparameters=hyperparameters,\n",
    "    framework_version=\"1.6.0\",\n",
    "    py_version=\"py3\",\n",
    "    train_max_run=3600,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    # Parameters required to enable spot training.\n",
    "    train_use_spot_instances=True,  # Set it to True to enable spot training.\n",
    "    train_max_wait=3600,  # This should be equal to or greater than train_max_run in seconds\n",
    "    checkpoint_s3_uri=checkpoint_s3_bucket,  # Set the S3 URI to store the checkpoints.\n",
    "    checkpoint_local_path=checkpoint_local_path,  # This is default path where checkpoints will be stored. The training script should generate the checkpoints.\n",
    "    ## Rule parameter\n",
    "    rules=[Rule.sagemaker(rule_configs.vanishing_gradient())],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "outside-polyester",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-27T00:12:09.212239Z",
     "iopub.status.busy": "2021-05-27T00:12:09.211770Z",
     "iopub.status.idle": "2021-05-27T00:16:16.420970Z",
     "shell.execute_reply": "2021-05-27T00:16:16.421456Z"
    },
    "papermill": {
     "duration": 247.21846,
     "end_time": "2021-05-27T00:16:16.421676",
     "exception": true,
     "start_time": "2021-05-27T00:12:09.203216",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-27 00:12:09 Starting - Starting the training job...\n",
      "2021-05-27 00:12:15 Starting - Launching requested ML instancesVanishingGradient: InProgress\n",
      "ProfilerReport-1622074329: InProgress\n",
      "......\n",
      "2021-05-27 00:13:25 Starting - Preparing the instances for training.........\n",
      "2021-05-27 00:15:03 Downloading - Downloading input data...\n",
      "2021-05-27 00:15:27 Training - Downloading the training image..\u001b[34m2021-05-27 00:15:49,440 sagemaker-training-toolkit INFO     Imported framework sagemaker_mxnet_container.training\u001b[0m\n",
      "\u001b[34m2021-05-27 00:15:49,443 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-05-27 00:15:49,458 sagemaker_mxnet_container.training INFO     MXNet training environment: {'SM_HOSTS': '[\"algo-1\"]', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'SM_HPS': '{\"batch-size\":100,\"checkpoint-path\":\"/opt/ml/checkpoints\",\"epochs\":5}', 'SM_USER_ENTRY_POINT': 'mxnet_gluon_spot_training.py', 'SM_FRAMEWORK_PARAMS': '{}', 'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}', 'SM_INPUT_DATA_CONFIG': '{}', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'SM_CHANNELS': '[]', 'SM_CURRENT_HOST': 'algo-1', 'SM_MODULE_NAME': 'mxnet_gluon_spot_training', 'SM_LOG_LEVEL': '20', 'SM_FRAMEWORK_MODULE': 'sagemaker_mxnet_container.training:main', 'SM_INPUT_DIR': '/opt/ml/input', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_NUM_CPUS': '4', 'SM_NUM_GPUS': '0', 'SM_MODEL_DIR': '/opt/ml/model', 'SM_MODULE_DIR': 's3://sagemaker-us-west-2-521695447989/smdebugger-spot-training-demo-mxnet-2021-05-27-00-12-09-210/source/sourcedir.tar.gz', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":100,\"checkpoint-path\":\"/opt/ml/checkpoints\",\"epochs\":5},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"smdebugger-spot-training-demo-mxnet-2021-05-27-00-12-09-210\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-521695447989/smdebugger-spot-training-demo-mxnet-2021-05-27-00-12-09-210/source/sourcedir.tar.gz\",\"module_name\":\"mxnet_gluon_spot_training\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"mxnet_gluon_spot_training.py\"}', 'SM_USER_ARGS': '[\"--batch-size\",\"100\",\"--checkpoint-path\",\"/opt/ml/checkpoints\",\"--epochs\",\"5\"]', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'SM_HP_BATCH-SIZE': '100', 'SM_HP_CHECKPOINT-PATH': '/opt/ml/checkpoints', 'SM_HP_EPOCHS': '5'}\u001b[0m\n",
      "\u001b[34m2021-05-27 00:15:49,813 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-05-27 00:15:52,844 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-05-27 00:15:52,862 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2021-05-27 00:15:52,876 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_mxnet_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 100,\n",
      "        \"checkpoint-path\": \"/opt/ml/checkpoints\",\n",
      "        \"epochs\": 5\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"smdebugger-spot-training-demo-mxnet-2021-05-27-00-12-09-210\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-521695447989/smdebugger-spot-training-demo-mxnet-2021-05-27-00-12-09-210/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"mxnet_gluon_spot_training\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"mxnet_gluon_spot_training.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":100,\"checkpoint-path\":\"/opt/ml/checkpoints\",\"epochs\":5}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=mxnet_gluon_spot_training.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=mxnet_gluon_spot_training\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_mxnet_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-521695447989/smdebugger-spot-training-demo-mxnet-2021-05-27-00-12-09-210/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":100,\"checkpoint-path\":\"/opt/ml/checkpoints\",\"epochs\":5},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"smdebugger-spot-training-demo-mxnet-2021-05-27-00-12-09-210\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-521695447989/smdebugger-spot-training-demo-mxnet-2021-05-27-00-12-09-210/source/sourcedir.tar.gz\",\"module_name\":\"mxnet_gluon_spot_training\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"mxnet_gluon_spot_training.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"100\",\"--checkpoint-path\",\"/opt/ml/checkpoints\",\"--epochs\",\"5\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=100\u001b[0m\n",
      "\u001b[34mSM_HP_CHECKPOINT-PATH=/opt/ml/checkpoints\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=5\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python36.zip:/usr/local/lib/python3.6:/usr/local/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.6 mxnet_gluon_spot_training.py --batch-size 100 --checkpoint-path /opt/ml/checkpoints --epochs 5\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mDownloading ./data/train-images-idx3-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/mnist/train-images-idx3-ubyte.gz...\u001b[0m\n"
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ThrottlingException) when calling the DescribeTrainingJob operation (reached max retries: 4): Rate exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-28be9b2c12b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1623\u001b[0m         \u001b[0;31m# If logs are requested, call logs_for_jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1624\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1625\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1626\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   3634\u001b[0m                 \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMPLETE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3635\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlast_describe_job_call\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3636\u001b[0;31m                 \u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe_training_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrainingJobName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3637\u001b[0m                 \u001b[0mlast_describe_job_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    356\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (ThrottlingException) when calling the DescribeTrainingJob operation (reached max retries: 4): Rate exceeded"
     ]
    }
   ],
   "source": [
    "estimator.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 249.723114,
   "end_time": "2021-05-27T00:16:16.917531",
   "environment_variables": {},
   "exception": true,
   "input_path": "mxnet-spot-training-with-sagemakerdebugger.ipynb",
   "output_path": "/opt/ml/processing/output/mxnet-spot-training-with-sagemakerdebugger-2021-05-27-00-07-51.ipynb",
   "parameters": {
    "kms_key": "arn:aws:kms:us-west-2:521695447989:key/6e9984db-50cf-4c7e-926c-877ec47a8b25"
   },
   "start_time": "2021-05-27T00:12:07.194417",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
